{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datacamp CapGemini\n",
    "#### Group 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aims : classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data = pd.read_csv('../data/labeled_data.csv', encoding='utf8')\n",
    "unlabeled_data = pd.read_csv('../data/data_unlabeled.csv', engine='c', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data[\"text\"].sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data[\"text\"].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classes = ['screen', 'software_bugs', 'locking_system', 'system', 'apps_update', 'battery_life_charging', 'customerservice']\n",
    "labeled_data.iloc[:, 1:].loc[:, selected_classes].apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining our preprocessing pipeline : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords as stpwrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    # Remove ponctuation\n",
    "    matrix = str.maketrans(\",\\\"_;\", \"    \", \"'’.()/-?!|:><&[]*=@%^â€™\")\n",
    "    df[\"text\"] = df[\"text\"].transform(lambda x: x.translate(matrix))\n",
    "    \n",
    "    # Remove bad characters\n",
    "    df[\"text\"] = df[\"text\"].transform(lambda text: ''.join([x for x in text if ord(x)<128 or ord(x)!=25]))\n",
    "    \n",
    "    # Remove hashtags\n",
    "    df[\"text\"] = df[\"text\"].map(lambda x: regex.sub('#[a-zA-Z0-9-]*', '', x))\n",
    "    \n",
    "    # Remove number only strings\n",
    "    numbers = regex.compile('^[0-9 ]+$')\n",
    "    mask = df[\"text\"].map(lambda x: not numbers.match(x))\n",
    "    df = df[mask]\n",
    "    \n",
    "    mask = df[\"text\"].map(lambda x: x.strip() == '')\n",
    "    df = df.loc[~mask]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df):\n",
    "    # Tokenize\n",
    "    tweet = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "    stopwords = set(stpwrds.words('english'))\n",
    "\n",
    "    df[\"text\"] = df[\"text\"].transform(tweet.tokenize)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    df[\"text\"] = df[\"text\"].transform(lambda x: [token for token in x if not token in stopwords])\n",
    "    \n",
    "    # Remove tokens with only numbers\n",
    "    numbers = regex.compile('^[0-9]{3,}$')\n",
    "    df[\"text\"] = df[\"text\"].map(lambda x: [token for token in x if not numbers.match(token)])\n",
    "    \n",
    "    # Number of tokens\n",
    "    df[\"length\"] = df[\"text\"].apply(lambda x: len(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect language\n",
    "import langdetect\n",
    "\n",
    "def detect_lang(x):\n",
    "    try: \n",
    "        return langdetect.detect(x)\n",
    "    except Exception as e:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tokens):\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_lemmatize(tokens, nlp):\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    return [token.lemma_.lower().strip() for token in doc if token.lemma_ != \"-PRON-\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom tokens\n",
    "def custom_lemmatize(tokens):\n",
    "    processed = []\n",
    "    extend = processed.extend\n",
    "    length = len(tokens)\n",
    "    \n",
    "    for i, token in enumerate(tokens):\n",
    "        # iPhones\n",
    "        if token == \"x\" or token == \"10\":\n",
    "            result = [\"10\"]\n",
    "            if i>0 and tokens[i-1] != \"iphone\":\n",
    "                result.insert(0, \"iphone\")\n",
    "            extend(result)\n",
    "            continue\n",
    "        if token in [\"6\", \"7\", \"8\"]:\n",
    "            result = [token]\n",
    "            if i>0 and tokens[i-1] != \"iphone\":\n",
    "                result.insert(0, \"iphone\")\n",
    "            extend(result)\n",
    "            continue\n",
    "        if token == \"+\":\n",
    "            extend([\"plus\"])\n",
    "        extend([token])\n",
    "        \n",
    "        # Samsung\n",
    "        if token == \"s8\":\n",
    "            result = [\"S8\"]\n",
    "            if i>0 and tokens[i-1] != \"samsung\":\n",
    "                result.insert(0, \"samsung\")\n",
    "            extend(result)\n",
    "            continue\n",
    "        \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(column):\n",
    "    phrases = Phrases(column.values.tolist())\n",
    "    bigrams = Phraser(phrases)\n",
    "    return list(bigrams[column.values.tolist()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_pipeline(df, threshold=4):\n",
    "    df = preprocess_text(df)\n",
    "    df = tokenize(df)\n",
    "    df['text'] = df['text'].progress_map(lambda x: spacy_lemmatize(x, nlp))\n",
    "    df['text'] = df['text'].apply(custom_lemmatize)\n",
    "    df['text'] = bigrams(df['text'])\n",
    "    df['text'] = df['text'].apply(lambda x: [tk for tk in x if tk])\n",
    "    df = df[df['text'].map(lambda x: len(x) > threshold)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word/sentence encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lbl_train, X_lbl_test = train_test_split(labeled_data, test_size=0.2, random_state=42, stratify=labeled_data['issue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = X_lbl_train.iloc[:, 1:].loc[:, selected_classes].apply(pd.value_counts)\n",
    "for cat, values in counts.iteritems():\n",
    "    print(\"{} - {:.2%} positives\".format(cat, values[1]/values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lbl_train = preprocessing_pipeline(X_lbl_train)\n",
    "X_lbl_test = preprocessing_pipeline(X_lbl_test)\n",
    "y_lbl_train = X_lbl_train['issue']\n",
    "y_lbl_test = X_lbl_test['issue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doc2Vec (what we use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs(sources):\n",
    "    for label, source in sources.items():\n",
    "        for i, tokens in source.iteritems():\n",
    "            yield TaggedDocument(words=tokens, tags=[\"{}_{}\".format(label, i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with train data\n",
    "sources = {\n",
    "    'TRAIN': X_lbl_train[\"text\"]\n",
    "}\n",
    "\n",
    "reviews = list(get_docs(sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(size=500, window=15, min_count=10, workers=10)\n",
    "model.build_vocab(reviews)\n",
    "model.train(reviews, epochs=20, total_examples=model.corpus_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2v(model, data, infer=True): \n",
    "    if infer:\n",
    "        vectors = [model.infer_vector(review) for review in data.values.tolist()]\n",
    "    else:\n",
    "        vectors = [model[\"TRAIN_{}\".format(i)] for i in data.index.values.tolist()]\n",
    "        \n",
    "    return pd.DataFrame(vectors, index=data.index, columns=[\"dim_{}\".format(i) for i in range(model.vector_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lbl_train_d2v = d2v(model, X_lbl_train['text'], infer=False)\n",
    "X_lbl_test_d2v = d2v(model, X_lbl_test['text'], infer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get vocabulary\n",
    "vocab = list(\n",
    "    set(itertools.chain(*X_lbl_train['text'].tolist()))|\n",
    "    set(itertools.chain(*X_lbl_test['text'].tolist()))|\n",
    "    set(itertools.chain(*X_unlbl['text'].tolist()))\n",
    ")\n",
    "vocab_dict = dict((y, x) for x, y in enumerate(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TfidfVectorizer(ngram_range=(1,3), use_idf=True, vocabulary=vocab_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lbl_train = model.fit_transform(X_lbl_train['text'].apply(lambda x: \" \".join(x)).values.tolist())\n",
    "X_lbl_test = model.transform(X_lbl_test['text'].apply(lambda x: \" \".join(x)).values.tolist())\n",
    "X_unlbl = model.transform(X_unlbl['text'].apply(lambda x: \" \".join(x)).values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost classification without label propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(max_depth=20, \n",
    "                    n_estimators=750, \n",
    "                    min_child_weight=3, \n",
    "                    scale_pos_weight=2,\n",
    "                    learning_rate=0.05, \n",
    "                    max_delta_step=0.5,\n",
    "                    gamma=0.01,\n",
    "                    colsample_bytree=0.8,\n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_lbl_train_d2v, y_lbl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_lbl_test, clf.predict(X_lbl_test_d2v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on unlabeled data (WIP - not used for the final prediction due to poor results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we use our classifier to predict issues on the unlabeled data : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlbl = preprocessing_pipeline(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlbl_d2v = d2v(model, X_unlbl['text'], infer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_predictions = pd.DataFrame(clf.predict_proba(X_unlbl_d2v)[:, 1], index=X_unlbl_d2v.index)\n",
    "\n",
    "unlabeled_data['xgb_issue_prob'] = issue_predictions\n",
    "# Drop rows if no issue proba\n",
    "unlabeled_data = unlabeled_data.dropna(subset=['xgb_issue_prob'])\n",
    "# Predict binary output according to a threshold\n",
    "unlabeled_data['xgb_issue'] = unlabeled_data['xgb_issue_prob'].apply(lambda x: x > 0.4).map(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data['xgb_issue'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we perform sentiment analysis in order to detect false positives :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unlabeled_data['sentiment'] = unlabeled_data[\"text\"].progress_map(sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cross results to spot weird matches :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_preds(row, prob_col_name=\"xgb_issue\", sentiment_col_name=\"sentiment\"):\n",
    "    return int(row[prob_col_name] == 1 and row[sentiment_col_name] <= 0)\n",
    "\n",
    "unlabeled_data['issue'] = unlabeled_data.apply(combine_preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_data['issue'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_all = XGBClassifier(max_depth=8, \n",
    "                        n_estimators=750, \n",
    "                        min_child_weight=3, \n",
    "                        scale_pos_weight=2,\n",
    "                        learning_rate=0.05, \n",
    "                        max_delta_step=0.5,\n",
    "                        gamma=0.01,\n",
    "                        n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = pd.concat([X_lbl_train_d2v, X_unlbl_d2v])\n",
    "y_all = pd.concat([y_lbl_train, unlabeled_data['issue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_all, y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_lbl_test, clf.predict(X_lbl_test_d2v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hackathon : multi-~~label~~ class problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to reduce the classification problem to a multiclass one :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_classes = ['screen', 'software_bugs', 'locking_system', 'system', 'apps_update', 'battery_life_charging', 'customerservice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new `issue` indicator column on the class subset and merge all classes dummy variables :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lbl_train['issue'] = X_lbl_train.loc[:, selected_classes].apply(lambda x: int(x.any()), axis=1)\n",
    "X_lbl_test['issue'] = X_lbl_test.loc[:, selected_classes].apply(lambda x: int(x.any()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_class(row):\n",
    "    if row['issue'] == 1:\n",
    "        issue_name = row.idxmax(1)\n",
    "        return selected_classes.index(issue_name)+1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lbl_train = X_lbl_train.loc[:, selected_classes + ['issue']].apply(encode_class, axis=1)\n",
    "y_lbl_test = X_lbl_test.loc[:, selected_classes + ['issue']].apply(encode_class, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the classifier on this categorical vector :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(max_depth=8, \n",
    "                    n_estimators=750, \n",
    "                    objective='multi:softprob',\n",
    "                    min_child_weight=3, \n",
    "                    scale_pos_weight=2,\n",
    "                    learning_rate=0.05, \n",
    "                    max_delta_step=0.5,\n",
    "                    gamma=0.01,\n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_lbl_train_d2v, y_lbl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_lbl_test, clf.predict(X_lbl_test_d2v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('../data/test_data.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = preprocessing_pipeline(test_data)\n",
    "X_test_d2v = d2v(model, X_test['text'], infer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(clf.predict_proba(X_test_d2v),\n",
    "                           index=X_test.index)\n",
    "predictions = predictions.drop(columns=[0])\n",
    "predictions.columns = selected_classes\n",
    "\n",
    "# We set a low threshold in order to maximize the recall\n",
    "predictions = predictions.applymap(lambda x: int(x>0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_test = pd.concat([test_data['text'], predictions], axis=1)\n",
    "X_y_test = X_y_test.fillna(0)\n",
    "X_y_test['issue'] = X_y_test.iloc[:, 1:].apply(lambda x: int(x.any()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview of the results\n",
    "mask = X_y_test.iloc[:, 2:].apply(lambda x: x.any(), axis=1)\n",
    "X_y_test[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to disk\n",
    "X_y_test.to_csv('../data/test_final.csv')\n",
    "X_y_test[mask].to_csv('../data/test_issues_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction on the unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(clf.predict_proba(X_unlbl_d2v),\n",
    "                           index=X_unlbl.index)\n",
    "predictions = predictions.drop(columns=[0])\n",
    "predictions.columns = selected_classes\n",
    "\n",
    "# We set a low threshold in order to maximize the recall\n",
    "predictions = predictions.applymap(lambda x: int(x>0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_unlbl = pd.concat([unlabeled_data['text'], predictions], axis=1)\n",
    "X_y_unlbl = X_y_unlbl.fillna(0)\n",
    "X_y_unlbl['issue'] = X_y_unlbl.iloc[:, 1:].apply(lambda x: int(x.any()), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = X_y_unlbl.loc[X_y_unlbl['issue'] == 1, :].iloc[:, 1:-1].apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col, values in counts.iteritems():\n",
    "    print('Feature category: {}'.format(col))\n",
    "    for i, v in values.iteritems():\n",
    "        print(\"{} - {}\".format(\"No\" if i == 0 else \"Yes\", v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = X_y_unlbl.iloc[:, 1:-1].apply(lambda x: x.any(), axis=1)\n",
    "X_y_unlbl[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_y_unlbl.to_csv('../data/propagation_unlbl_final.csv')\n",
    "X_y_unlbl[mask].to_csv('../data/unlbl_issues_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
